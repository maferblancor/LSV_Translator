{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfreeling as freeling\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_dict(file_path):\n",
    "    final_list = ''\n",
    "    with open(file_path) as lines:\n",
    "        for lineItem in lines:\n",
    "            attribute = lineItem.split(':')[0]\n",
    "            try:\n",
    "                value = lineItem.split(':')[1]\n",
    "            except:\n",
    "                value = lineItem\n",
    "                #print ('--->Falta por clasificar')\n",
    "            final_list = final_list + (attribute+':'+value+',')\n",
    "    final_list = final_list.rstrip(',').replace('\\n','').replace(' ','') \n",
    "    lines_dict = dict((k,v) for k, v in (e.split(':') for e in final_list.split(',')))\n",
    "    return lines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_maco_options(lang,lpath) :\n",
    "\n",
    "    # create options holder \n",
    "    opt = freeling.maco_options(lang);\n",
    "\n",
    "    # Provide files for morphological submodules. Note that it is not \n",
    "    # necessary to set file for modules that will not be used.\n",
    "    opt.UserMapFile = \"\";\n",
    "    opt.LocutionsFile = lpath + \"locucions.dat\"; \n",
    "    opt.AffixFile = lpath + \"afixos.dat\";\n",
    "    opt.ProbabilityFile = lpath + \"probabilitats.dat\"; \n",
    "    opt.DictionaryFile = lpath + \"dicc.src\";\n",
    "    opt.NPdataFile = lpath + \"np.dat\"; \n",
    "    opt.PunctuationFile = lpath + \"../common/punct.dat\"; \n",
    "    return opt;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_value(line, re_value, group_number = 0): \n",
    "    value = re.search(re_value,line)\n",
    "    if not value:\n",
    "        return None \n",
    "    value = value.group(group_number)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(token, list_):\n",
    "    for iterator in list_:    \n",
    "        val = get_re_value(token, iterator)\n",
    "        if val:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_something(syns,categories):\n",
    "    is_top = False\n",
    "    is_label = False\n",
    "    for syn in syns:\n",
    "        while not is_label:\n",
    "            si = sdb.get_sense_info(syn)\n",
    "            for label in categories:\n",
    "                is_label = (si.sumo == label)\n",
    "                if is_label:\n",
    "                    is_top = True\n",
    "                    break\n",
    "                else:\n",
    "                    if len(si.parents) > 0 :\n",
    "                        syn = si.parents[0]\n",
    "                        continue\n",
    "                    else:\n",
    "                        is_top = True\n",
    "                        is_label = 'NoValid'\n",
    "                        break\n",
    "        if is_label != 'NoValid':\n",
    "            return (categories[label])\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sumo_tag(syns,label):\n",
    "    is_top = False\n",
    "    is_label = False\n",
    "    while not is_label:\n",
    "        si = sdb.get_sense_info(syns)\n",
    "        is_label = (si.sumo == label)\n",
    "        if is_label:\n",
    "            is_top = True\n",
    "            break\n",
    "        else:\n",
    "            if len(si.parents) > 0 :\n",
    "                syns = si.parents[0]\n",
    "                continue\n",
    "            else:\n",
    "                is_top = True\n",
    "                is_label = 'NoValid'\n",
    "                break\n",
    "    if is_label != 'NoValid':\n",
    "        return (label)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_gender_number(tag):\n",
    "    #DAOFS0\n",
    "    #gender = [3]\n",
    "    #number = [4]\n",
    "    gender = '' ; number = ''\n",
    "    if tag[3] == 'F' or tag[2] == 'F': gender = '(F)'\n",
    "    if tag[3] == 'M' or tag[2] == 'M': gender = ''\n",
    "    if tag[3] == 'N' or tag[2] == 'N': gender = ''\n",
    "    if tag[4] == 'S' or tag[3] == 'S': number = ''\n",
    "    if tag[4] == 'P' or tag[3] == 'P': number = '(x2)'\n",
    "    if tag[4] == 'N' or tag[3] == 'N': number = ''\n",
    "    return (gender, number)    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_syns_tag(syns,label):\n",
    "    is_top = False ; is_label = False\n",
    "    for syn in syns:\n",
    "        while not is_label and not is_top:\n",
    "            si = sdb.get_sense_info(syn)\n",
    "            is_label = (si.sumo == label)\n",
    "            if is_label:\n",
    "                is_top = True\n",
    "                return True\n",
    "            else:\n",
    "                if len(si.parents) > 0 :\n",
    "                    syn = si.parents[0]\n",
    "                else:\n",
    "                    is_top = True\n",
    "        is_top = False ; is_label = False\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(tag):    \n",
    "    if tag[3] == 'P' or tag[2] == 'G' : return 'Presente'\n",
    "    if tag[3] == 'F' : return 'Futuro'\n",
    "    if tag[3] == 'S' or tag[3] == 'I'  : return 'Pasado'\n",
    "    return ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_info(word):\n",
    "    if len(word.get_senses())>0:\n",
    "        try:\n",
    "            syns = (word.get_senses()[0][0],word.get_senses()[1][0])\n",
    "        except:\n",
    "            syns = (word.get_senses()[0][0])\n",
    "    else:\n",
    "        syns = '' \n",
    "    return word.get_tag(),word.get_lemma(),word.get_form(),syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expresions(tag,expresions, expresions_final):\n",
    "    expre = ''\n",
    "    if tag[0:3] in expresions_final:\n",
    "        expre = (expresions_final[tag[0:3]])\n",
    "        expre = ''\n",
    "    else:\n",
    "        if tag[0:3] in expresions:\n",
    "            expre =(expresions[tag[0:3]])\n",
    "    return expre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell(name): \n",
    "    spell_name = ''\n",
    "    for letter in name:\n",
    "        spell_name = spell_name +str.upper(letter)+ '-'\n",
    "    return spell_name.rstrip('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(tag):\n",
    "    if tag[3] == 'P' : return 'X2'\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessSentences(ls, sdb,exceptions,categories,expresions, expresion_final):    \n",
    "    expre = '' ; gender = ''; number = '' ; time = '' ; verb_aux = False ; verb_number = False\n",
    "    out = {'tag':[],'lemma':[],'word':[],'expresion':[],'number':[],'gender':[],'time':[]}\n",
    "    for s in ls :\n",
    "        for w, itera in zip(s , range(len(s))):    \n",
    "            tag,lemma,word,syns = get_word_info(w)\n",
    "            prev_word_tag,prev_word_lemma,prev_word_form, prev_word_syns = get_word_info(s[itera-1])\n",
    "            expre = get_expresions(tag, expresions, expresions_final)\n",
    "            if tag[0] == 'N':\n",
    "                if (tag[0:2] == 'NC'):\n",
    "                    if not is_syns_tag(syns,'Human='):\n",
    "                        verb_number = get_number(tag)\n",
    "                        gender = '' ; number =''\n",
    "                    else:\n",
    "                        (gender, number)= analize_gender_number(tag)\n",
    "                else:\n",
    "                    #Se deletran los nombres propios.\n",
    "                    lemma = spell(word)         \n",
    "            if tag[0:2] == 'DA' or tag[0:2] == 'DI':\n",
    "                (gender,number) = analize_gender_number(tag) \n",
    "                #continue\n",
    "            if tag[0] == 'V':\n",
    "                if verb_number:\n",
    "                    number = verb_number\n",
    "                if (tag[0:2] == 'VA' or tag[0:2] == 'VS'):\n",
    "                    time = get_time(tag)\n",
    "                    verb_aux = True\n",
    "                elif tag[0:2] == 'VM':\n",
    "                    if verb_aux == False:\n",
    "                        time = get_time(tag)\n",
    "                    #Es verbo principal\n",
    "            #Reviso la pertenencia al contexto \n",
    "            tok = is_something(syns,categories)\n",
    "            if tok:\n",
    "                lemma = tok\n",
    "            if (clean_input(list_=exceptions,token=tag) or lemma == 'estar' or lemma == 'ser'):\n",
    "                continue\n",
    "            out['tag'].append(tag);out['lemma'].append(str.upper(lemma));out['word'].append(word)\n",
    "            out['expresion'].append(expre);out['gender'].append(gender);out['number'].append(number);out['time'].append(time)\n",
    "            gender = '';number =''; time =''     \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeling.util_init_locale(\"default\");\n",
    "lang = \"es\" ; ipath = \"/usr\"\n",
    "lpath = ipath + \"/share/freeling/\" + lang + \"/\"\n",
    "tk=freeling.tokenizer(lpath+\"tokenizer.dat\");\n",
    "sp=freeling.splitter(lpath+\"splitter.dat\");\n",
    "morfo=freeling.maco(my_maco_options(lang,lpath));\n",
    "morfo.set_active_options (False,  # UserMap \n",
    "                          True,  # NumbersDetection,  \n",
    "                          True,  # PunctuationDetection,   \n",
    "                          True,  # DatesDetection,    \n",
    "                          True,  # DictionarySearch,  \n",
    "                          True,  # AffixAnalysis,  \n",
    "                          False, # CompoundAnalysis, \n",
    "                          True,  # RetokContractions,\n",
    "                          True,  # MultiwordsDetection,  \n",
    "                          True,  # NERecognition,     \n",
    "                          False, # QuantitiesDetection,  \n",
    "                          True); # ProbabilityAssignment                 \n",
    "tagger = freeling.hmm_tagger(lpath+\"tagger.dat\",True,2)\n",
    "# create sense annotator\n",
    "sen = freeling.senses(lpath+\"senses.dat\");\n",
    "# create sense disambiguator\n",
    "wsd = freeling.ukb(lpath+\"ukb.dat\");\n",
    "sdb = freeling.semanticDB(lpath+\"semdb.dat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions=['^PR0','^P0','^DI','^DA','Fd','Flt','Fla','Fe','Frc','Fra','Fx', 'Faa','Fat','Fia','Fit','Fp']\n",
    "categories = txt_to_dict('categories.txt') ; expresions = txt_to_dict('expresions.txt') ; expresions_final = txt_to_dict('expresions_final.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:Yo soy Aurora.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag        lemma    word expresion gender number      time\n",
      "0  PP1CSN0           YO      Yo                                  \n",
      "1  NP00000  A-U-R-O-R-A  Aurora                          Presente\n",
      "\n",
      "\n",
      "Input:¡Hola! ¿Cuál es tu nombre? Mi nombre es José.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag    lemma    word      expresion gender number      time\n",
      "0        I     HOLA    Hola    EXCLAMACION                        \n",
      "1  PT0CS00     CUÁL    Cuál  INTERROGACION                        \n",
      "2   DP2CSS       TU      tu                               Presente\n",
      "3  NCMS000   NOMBRE  nombre                                       \n",
      "4   DP1CSS       MI      Mi                                       \n",
      "5  NCMS000   NOMBRE  nombre                                       \n",
      "6  NP00000  J-O-S-É    José                               Presente\n",
      "\n",
      "\n",
      "Input:Yo tenía un perro que se llamaba Pancho.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag        lemma     word expresion gender number    time\n",
      "0  PP1CSN0           YO       Yo                                \n",
      "1  VMII3S0        TENER    tenía                          Pasado\n",
      "2  NCMS000      ANIMAL+    perro                                \n",
      "3  VMII3S0       LLAMAR  llamaba                          Pasado\n",
      "4  NP00000  P-A-N-C-H-O   Pancho                                \n",
      "\n",
      "\n",
      "Input:Una niña camina en el parque.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag    lemma    word expresion gender number      time\n",
      "0  NCFS000     NIÑO    niña              (F)                 \n",
      "1  VMIP3S0  CAMINAR  camina                          Presente\n",
      "2       SP       EN      en                                  \n",
      "3  NCMS000   PARQUE  parque                                  \n",
      "\n",
      "\n",
      "Input:Un niño camina en la plaza.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag    lemma    word expresion gender number      time\n",
      "0  NCMS000     NIÑO    niño                                  \n",
      "1  VMIP3S0  CAMINAR  camina                          Presente\n",
      "2       SP       EN      en                                  \n",
      "3  NCFS000    PLAZA   plaza                                  \n",
      "\n",
      "\n",
      "Input:Un hombre agarra frutas.\n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag              lemma    word expresion gender number      time\n",
      "0  NCMS000             HOMBRE  hombre                                  \n",
      "1  VMIP3S0            AGARRAR  agarra                          Presente\n",
      "2  NCFP000  FRUITORVEGETABLE=  frutas                                  \n",
      "\n",
      "\n",
      "Input:Unas niñas caminaban en la plaza.\n",
      "\n",
      "Output:\n",
      "\n",
      "       tag    lemma       word expresion gender number    time\n",
      "0  NCFP000     NIÑO      niñas              (F)   (x2)        \n",
      "1  VMII3P0  CAMINAR  caminaban                          Pasado\n",
      "2       SP       EN         en                                \n",
      "3  NCFS000    PLAZA      plaza                                \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''; prev_expre = ''; order = ['tag','lemma','word','expresion','gender','number','time']\n",
    "f = open ('out.txt','w')\n",
    "with open('input.txt') as lineas:    \n",
    "    for text in lineas:\n",
    "        if text == '':\n",
    "            break\n",
    "        lw = tk.tokenize(text.replace('\\n',''))\n",
    "        # split list of words in sentences, return list of sentences\n",
    "        ls = sp.split(lw)\n",
    "\n",
    "        # perform morphosyntactic analysis and disambiguation\n",
    "        ls = morfo.analyze(ls)\n",
    "        ls = tagger.analyze(ls)\n",
    "        ls = sen.analyze(ls);\n",
    "        ls = wsd.analyze(ls);\n",
    "        # create semantic DB module\n",
    "        \n",
    "        # do whatever is needed with processed sentences \n",
    "        print ('Input:'+text+'\\n')\n",
    "        print ('Output:'+'\\n')\n",
    "        out = ProcessSentences(ls,sdb, exceptions, categories, expresions, expresions_final)\n",
    "        out = pd.DataFrame(out)\n",
    "        print (out[order])\n",
    "        print ('\\n')\n",
    "        f.write('\\nInput:'+text+'\\n')\n",
    "        f.write('Output:'+'\\n')\n",
    "        f.write(out[order].to_string())\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
