{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSV import *\n",
    "import pyfreeling as freeling\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeling.util_init_locale(\"default\");\n",
    "lang = \"es\" ; ipath = \"/usr\"\n",
    "lpath = ipath + \"/share/freeling/\" + lang + \"/\"\n",
    "tk=freeling.tokenizer(lpath+\"tokenizer.dat\");\n",
    "sp=freeling.splitter(lpath+\"splitter.dat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "morfo=freeling.maco(my_maco_options(lang,lpath));\n",
    "morfo.set_active_options (False,  # UserMap \n",
    "                          True,  # NumbersDetection,  \n",
    "                          True,  # PunctuationDetection,   \n",
    "                          True,  # DatesDetection,    \n",
    "                          True,  # DictionarySearch,  \n",
    "                          True,  # AffixAnalysis,  \n",
    "                          False, # CompoundAnalysis, \n",
    "                          True,  # RetokContractions,\n",
    "                          True,  # MultiwordsDetection,  \n",
    "                          True,  # NERecognition,     \n",
    "                          False, # QuantitiesDetection,  \n",
    "                          True); # ProbabilityAssignment                 \n",
    "tagger = freeling.hmm_tagger(lpath+\"tagger.dat\",True,2)\n",
    "# create sense annotator\n",
    "sen = freeling.senses(lpath+\"senses.dat\");\n",
    "# create sense disambiguator\n",
    "wsd = freeling.ukb(lpath+\"ukb.dat\");\n",
    "sdb = freeling.semanticDB(lpath+\"semdb.dat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions=['^PR0','^P0','^DI','^DA','Fd','Flt','Fla','Fe','Frc','Fra','Fx', 'Faa','Fat','Fia','Fit','Fp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:La peste. Los limones estaban amargos. La piedra es arenosa. \n",
      "\n",
      "Output:\n",
      "\n",
      "       tag    lemma     word expresion gender number      time\n",
      "0  NCFS000     OLOR    peste                                  \n",
      "1  NCMP000    SABOR  limones                                  \n",
      "2  AQ0MP00   AMARGO  amargos                      X2    Pasado\n",
      "3  NCFS000   PIEDRA   piedra                                  \n",
      "4  AQ0FS00  ARENOSO  arenosa                          Presente\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = txt_to_dict('categories.txt') ; expresions = txt_to_dict('expresions.txt') ; expresions_final = txt_to_dict('expresions_final.txt')\n",
    "text = ''; prev_expre = ''; order = ['tag','lemma','word','expresion','gender','number','time']\n",
    "f = open ('out.txt','w')\n",
    "with open('input.txt') as lineas:    \n",
    "    for text in lineas:\n",
    "        if text == '':\n",
    "            break\n",
    "        lw = tk.tokenize(text.replace('\\n',''))\n",
    "        # split list of words in sentences, return list of sentences\n",
    "        ls = sp.split(lw)\n",
    "        # perform morphosyntactic analysis and disambiguation\n",
    "        ls = morfo.analyze(ls)\n",
    "        ls = tagger.analyze(ls)\n",
    "        ls = sen.analyze(ls);\n",
    "        ls = wsd.analyze(ls);\n",
    "        # create semantic DB module\n",
    "        \n",
    "        # do whatever is needed with processed sentences \n",
    "        print ('Input:'+text+'\\n')\n",
    "        print ('Output:'+'\\n')\n",
    "        out = ProcessSentences(ls,sdb, exceptions, categories, expresions, expresions_final)\n",
    "        out = pd.DataFrame(out)\n",
    "        print (out[order])\n",
    "        print ('\\n')\n",
    "        f.write('\\nInput:'+text+'\\n')\n",
    "        f.write('Output:'+'\\n')\n",
    "        f.write(out[order].to_string())\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
